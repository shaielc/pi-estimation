{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HW2 Notebook\n",
    "- **In this assignment, when you are asked to provide an OpenMP parallel implementation to serial codes, you are expected to optimize your parallel code as much as possible using OpenMP constructs, directives, and clauses we learned in class so far. Your goal is to make the programs run in the minimum runtime possible.**    \n",
    "\n",
    "With OpenMP, if you do not set the number of threads, it will use the number of logical CPU cores. Sometimes, hyper-threading can reduce performance, and therefore, you are encouraged to try running with a different number of threads. \\\n",
    "You are encouraged to check these specifications with ```lscpu```, ```numactl --hardware``` and ```cat /proc/cpuinfo``` commands on this dedicated hardware.\n",
    "- **As in the previous assignment, the _.sh._ files include the compilation of the source files (we use the _icx_ compiler).** \n",
    "- **In this assignment, we compile all the programs with -O0 (no additional optimizations by the compiler).**\n",
    "- **Pay attention to keeping the timers wrapping the same work as the serial codes give.**\n",
    "\n",
    "**Use this notebook to compile your files, submit your jobs to Intel DevCloud nodes and observe/analyze your results.**\n",
    "## Submittion instructions\n",
    "- **Publication Date: 9/6.**\n",
    "- **Submission Date: 29/6**.\n",
    "- **Submitting in groups of up to 2 students (individually or in pairs).** \n",
    "- **Submission on moodle, in zip/tar format including this directory with the relevant output, specifically:** \n",
    "  - the source files.\n",
    "  - this notebook (run_hw2.ipynb) after executing all the cells. \n",
    "  - output files of queued jobs that might be created during the execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fill the name and ID of the submitters:\n",
    "#### Student Name: Shy-El Cohen Student ID: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem 1: Matrix Multiplication (10 points)\n",
    "\n",
    "<img src=\"attachment:2a316641-5236-4572-85f2-a55b53a37cb5.png\" width=\"500\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser('~')+'/HW2/MatMul')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the file _matmul_parallel.c_ to create an OpenMP implementation to the matrix multiplication problem defined in _matmul_serial.c_.** \\\n",
    "**Then, run the following cells:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat matmul_serial.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run_matmul_serial.sh; ./run_matmul_serial.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat matmul_parallel.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run_matmul_parallel.sh; ./run_matmul_parallel.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem 2: LU (15 points)\n",
    "\n",
    "<img src=\"attachment:2565eaea-5ff8-4312-b06e-05d1412e5396.PNG\" width=\"500\" />\n",
    "\n",
    "In numerical analysis and linear algebra, **lowerâ€“upper (LU)** decomposition or factorization factors a matrix as the product of a lower triangular matrix and an upper triangular matrix (see matrix decomposition).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser('~')+'/HW2/LU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the file _LU_parallel.c_ to create an OpenMP implementation to the LU serial solver defined in _LU_serial.c_.** \\\n",
    "**Then, run the following cells:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat LU_serial.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run_LU_serial.sh; ./run_LU_serial.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat LU_parallel.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run_LU_parallel.sh; ./run_LU_parallel.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: The n-body problem (20 points)\n",
    "\n",
    "In physics, the **n-body** problem is the problem of predicting the individual motions of a group of celestial objects interacting with each other gravitationally. Solving this problem has been motivated by the desire to understand the motions of the Sun, Moon, planets, and visible stars.\n",
    "\n",
    "<img src=\"attachment:1a5fb33e-3108-4feb-9cf0-5f14d92b9560.png\" width=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser('~')+'/HW2/n-body')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the file _n-body_parallel.c_ to create an OpenMP implementation to the n-body implementation defined in _n-body_serial.c_.** \\\n",
    "**Then, run the following cells:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat n-body_serial.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run_n-body_serial.sh; ./run_n-body_serial.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat n-body_parallel.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run_n-body_parallel.sh; ./run_n-body_parallel.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: First Touch (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **First Touch** placement policy allocates the data page in the memory closest to the thread accessing this page for the first time. This policy is the default on Linux and other OSes, and makes sense because it is the right thing to do for a sequential application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser('~')+'/HW2/FirstTouch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this exercise we will demonstrate the effect of thread and memory affinity in a multi-NUMA system.** \\\n",
    "In this exercise we demonstrate how NUMA-aware programing is important. In this problem, you need to check for the performance of a simple computation (**DAXPY**, i.e., **double precision aX+Y**), using varying number of threads and with different thread and memory affinity options. \n",
    "\n",
    "**Use the file _FirstTouch.c_ to execute, and fill the relevant results on the following graph.** \n",
    "- The code section in **1a** initializes the data using one single thread (the main thread). \n",
    "- The code section in **1b** initializes the data using all the threads (each initializes the part it will work on - later). \n",
    "- Use the macro **#define NTHREADS** to easily tune the numebr of threads. \n",
    "- Set the environment variable **OMP_PROC_BIND** to change OpenMP thread binding policy (close or spread). You can easily set the value of this variable with the export command (see in the _run.c_ file).  \n",
    "- Uncomment the relevant part of initialization (1a or 1b) in the file to test the relevant parts. \n",
    "- Use the following cell to run easily (You also may create an automatic script to run all the permutations if it is easier to you)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run.sh; ./run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "threads = [1,2,4,6,8,10,12,14,16,18,20,22,24]\n",
    "time_close_1a = [0,0,0,0,0,0,0,0,0,0,0,0,0] #edit these values\n",
    "time_close_1b = [0,0,0,0,0,0,0,0,0,0,0,0,0] #edit these values\n",
    "time_spread_1a = [0,0,0,0,0,0,0,0,0,0,0,0,0] #edit these values\n",
    "time_spread_1b = [0,0,0,0,0,0,0,0,0,0,0,0,0] #edit these values\n",
    "\n",
    "plt.plot(threads, time_close_1a, label = \"exec_time_close_1a\")\n",
    "plt.plot(threads, time_close_1b, label = \"exec_time_close_1b\")\n",
    "plt.plot(threads, time_spread_1a, label = \"exec_time_spread_1a\")\n",
    "plt.plot(threads, time_spread_1b, label = \"exec_time_spread_1b\")\n",
    "\n",
    "# naming the x axis\n",
    "plt.xlabel('Number of Threads')\n",
    "# naming the y axis\n",
    "plt.ylabel('Runtime of DAXPY with First Touch (sec)')\n",
    "# giving a title to my graph\n",
    "plt.title('Memory and Thread affinity impact on performances of DAXPY (lower is better!)')\n",
    "plt.grid()\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "  \n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain the results in the following cell. Focus on the differences between the various trends.**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Edit your answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Stencil Computation with Tasks (30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser('~')+'/HW2/Gauss-Seidel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we adress a 2D example of **stencil computation**. In this example, each cell depends on 4 neighbors (left, top, right, bottom). Each cell depends on two cells that are computed in the current time step (left, top), and two cells that were computed in the previous time step (right, bottom). The following figure illustrates this pattern on computation.\n",
    "\n",
    "<img src=\"attachment:df240c5e-d292-43a8-b296-bfea031f2cba.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following serial code (in _GS_serial.c_) computes the mentioned stencil probem on a grid of size 6002x6002 over 100 time steps (as you can see, the borders are not updated during the computation). \\\n",
    "**Run the following cells to see the performance of the serial execution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat GS_serial.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run_GS_serial.sh; ./run_GS_serial.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelization of a stencil computation might be non-trivial. One way to insert some sort of parallelism in a more natural way is by using OpenMP tasks. \\\n",
    "**Edit the file _GS_tasks_parallel.c_ to insert OpenMP tasks to the function _gauss_seidel_. In this part of the problem you are requested to create one task per each update of ```p[i][j]```. This can be done without any changes in the code (except adding OpenMP pragma directives).** \\\n",
    "Hint: be aware of dependences between different tasks you create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat GS_tasks_parallel.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are not requested to execute this implementation, because running this parallel implementation on the previous problem (6002x6002 grid over 100 time steps) may take long long time... \\\n",
    "**Can you guess why?**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Edit your ideas here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a much more efficient parallel implementation, we will try to insert more work into each task, ending up with much fewer number of tasks. The following figure illustrates that each task now updates an entire block of values in the grid. Each block is of size _TSxTS_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attachment:d48f8105-80b9-480f-ba55-1cb2680d79e3.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edit the file _GS_tasks_blocks_parallel.c_ to create a task-based parallel version based on blocks of updates. You may change the code as long as you need to. Again, be aware of task dependences that should be addressed. Tune the number of threads (NTHREADS) and the size of the block (TS) to achieve better performances.** \\\n",
    "Note: the block size (TS) must be chosen such that the whole grid (without the borders) is divided perfectly into such blocks. In our exmaple, TS should divide the number 6000. \\\n",
    "**Then, run the following cells:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat GS_tasks_blocks_parallel.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run_GS_tasks_blocks_parallel.sh; ./run_GS_tasks_blocks_parallel.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain the results. If you see any speedup, try to explain what kind of tasks could be executed in parallel?**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Edit your answer here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
